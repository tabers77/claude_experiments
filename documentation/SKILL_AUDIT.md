# Skill Audit: claude-library

> Generated by `/meta-skill-audit` on 2026-02-13

## Component Inventory

### Skills (20)

| # | Component | Type | Phase | Purpose |
|---|-----------|------|-------|---------|
| 1 | architecture-arch | Skill | Setup & Onboarding | Build mental model before touching code |
| 2 | meta-project-setup | Skill | Setup & Onboarding | Analyze project, recommend artifacts, detect gaps |
| 3 | quality-review | Skill | Setup & Onboarding | Repo-wide health audit with scoring + priority matrix |
| 4 | quality-upgrade-advisor | Skill | Setup & Onboarding | Audit dependencies, produce upgrade roadmap |
| 5 | learning-codebase-mastery | Skill | Setup & Onboarding | Deep understanding through quizzes and exercises |
| 6 | planning-impl-plan | Skill | Planning & Design | Design implementation approach before coding |
| 7 | planning-spec-from-text | Skill | Planning & Design | Turn vague requirements into testable specs |
| 8 | learning-pair-programming | Skill | Building | Pair program on real tasks with Claude as guide |
| 9 | api-development-api-impl | Skill | Building | Implement API endpoints with consistent patterns |
| 10 | code-diagnosis | Skill | Reviewing & Refactoring | Targeted scan for bugs, smells, refactoring opportunities |
| 11 | safe-changes-impact-check | Skill | Reviewing & Refactoring | Assess blast radius before risky changes |
| 12 | safe-changes-refactor-safe | Skill | Reviewing & Refactoring | Refactor with explicit invariants and checkpoints |
| 13 | session-wrapup | Skill | Wrapping Up | Record progress, sync docs, set next steps |
| 14 | learning-algo-practice | Skill | Skill Building | Algorithm & interview prep (DSA, SQL, pandas, ML) |
| 15 | learning-concept-recall | Skill | Skill Building | Spaced repetition for DS/engineering concepts |
| 16 | learning-debug-training | Skill | Skill Building | Systematic debugging training |
| 17 | learning-code-review-eye | Skill | Skill Building | Train code review skills on diffs |
| 18 | meta-experiment-feature | Skill | Library Maintenance | Set up experiments for new Claude Code features |
| 19 | meta-skill-audit | Skill | Library Maintenance | Audit library for overlaps and gaps |
| 20 | meta-update-docs | Skill | Library Maintenance | Fix stale cross-references across files |

### Agents (1)

| # | Component | Tools | Model | Purpose |
|---|-----------|-------|-------|---------|
| 1 | code-reviewer | Read, Grep, Glob, Bash | sonnet | Review recent code changes for quality, security, maintainability |

### Hooks (4)

| # | Event | Matcher | Purpose |
|---|-------|---------|---------|
| 1 | PreToolUse | Edit\|Write | Block edits to protected paths (protected/, migrations/, .env) |
| 2 | PreToolUse | Bash | Block destructive git commands (push --force, reset --hard, clean -f) |
| 3 | PostToolUse | Edit\|Write | Auto-lint Python files with ruff |
| 4 | PostToolUse | Edit\|Write | Alert on sensitive file modifications (config, secret, auth) |

### Rules (4)

| # | File | Topic | Key Conventions |
|---|------|-------|-----------------|
| 1 | api.md | API Development | RESTful naming, Pydantic validation, standardized errors, async endpoints |
| 2 | security.md | Security | Secrets via env vars, input validation, auth at boundary, safe logging |
| 3 | style.md | Code Style | ruff/black formatting, naming conventions, type hints, import ordering |
| 4 | testing.md | Testing | Unit/integration separation, naming pattern, 90%+ critical coverage |

---

## Overlap Analysis

### 1. [Low] planning-impl-plan vs learning-pair-programming

- **Components**: `planning-impl-plan` vs `learning-pair-programming`
- **Severity**: Low
- **What overlaps**: Both produce an implementation plan at the start. Both involve stepping through a task.
- **Key difference**: `impl-plan` produces a plan for **Claude to execute**. `pair-programming` produces a plan for **the user to execute** with Claude coaching. The planning step is similar but the entire execution model is different.
- **Recommendation**: Keep separate. Already differentiated in `pair-programming` SKILL.md ("vs `/planning-impl-plan`" section). No action needed.

### 2. [Low] code-diagnosis vs code-reviewer agent

- **Components**: `code-diagnosis` (skill) vs `code-reviewer` (agent)
- **Severity**: Low
- **What overlaps**: Both find issues in code. Both flag bugs, anti-patterns, and quality problems.
- **Key difference**: `code-diagnosis` scans a **specific module/file** the user points at (proactive investigation). `code-reviewer` reviews **recent git diff changes** (reactive review after writing). Different triggers, different scope.
- **Recommendation**: Keep separate. Already differentiated in `code-diagnosis` SKILL.md ("not a recent diff — use code-reviewer agent for that"). No action needed.

### 3. [Low] architecture-arch vs learning-codebase-mastery

- **Components**: `architecture-arch` vs `learning-codebase-mastery`
- **Severity**: Low
- **What overlaps**: Both help understand a codebase. Both read and analyze code structure.
- **Key difference**: `architecture-arch` produces a **reference document** (structural map). `codebase-mastery` teaches through **quizzes and exercises** (active learning). One is a deliverable, the other is a learning experience.
- **Recommendation**: Keep separate. Already differentiated in `codebase-mastery` SKILL.md ("vs `/architecture-arch`" section). No action needed.

### 4. [Low] learning-debug-training vs code-diagnosis

- **Components**: `learning-debug-training` vs `code-diagnosis`
- **Severity**: Low
- **What overlaps**: Both involve finding bugs in code.
- **Key difference**: `debug-training` presents **synthetic buggy code** for practice. `code-diagnosis` scans **real production code** for actual issues. One is learning, the other is production use.
- **Recommendation**: Keep separate. No confusion in practice — different contexts entirely.

### 5. [Low] learning-code-review-eye vs code-reviewer agent

- **Components**: `learning-code-review-eye` vs `code-reviewer` (agent)
- **Severity**: Low
- **What overlaps**: Both are about code review.
- **Key difference**: `code-review-eye` **trains the user** to spot issues (Claude shows diffs, user finds problems). `code-reviewer` is an **automated agent** that does the review for you. One builds skill, the other does the work.
- **Recommendation**: Keep separate. Complementary — use `code-reviewer` for real work, `code-review-eye` to train yourself.

### 6. [Low] quality-review vs quality-upgrade-advisor

- **Components**: `quality-review` vs `quality-upgrade-advisor`
- **Severity**: Low
- **What overlaps**: Both assess project quality. Both could be used during onboarding.
- **Key difference**: `quality-review` is a **broad health audit** across 8 categories (tests, security, architecture, etc.). `quality-upgrade-advisor` focuses specifically on **dependency ecosystem currency** (stale packages, deprecated patterns). One is wide, the other is deep on dependencies.
- **Recommendation**: Keep separate. `quality-review` might flag "dependencies are outdated" as one finding; `upgrade-advisor` goes deep on exactly which ones and how to upgrade.

### 7. [Low] safe-changes-impact-check vs safe-changes-refactor-safe

- **Components**: `safe-changes-impact-check` vs `safe-changes-refactor-safe`
- **Severity**: Low
- **What overlaps**: Both deal with making safe changes to code.
- **Key difference**: Sequential workflow — `impact-check` assesses **blast radius before** making changes (analysis). `refactor-safe` guides the **actual refactoring** with invariants and checkpoints (execution). One is "should I?" the other is "how do I?".
- **Recommendation**: Keep separate. They form a natural pipeline: impact-check first, then refactor-safe.

### Summary

**No High or Medium overlaps detected.** All 7 detected overlaps are Low severity — components share scenarios but serve distinct purposes. The existing "vs" documentation in several SKILL.md files already clarifies boundaries well.

---

## Gap Analysis

| Area | Priority | Current Coverage | Suggestion |
|------|----------|-----------------|------------|
| **Testing strategy** | Medium | Rules enforce test conventions. No skill designs test plans or analyzes coverage gaps. | Could extend `quality-review` to include a test strategy section, or create a `planning-test-strategy` skill that designs test plans for new features (what to test, what level, what mocks). |
| **Security review** | Medium | Rules enforce security conventions. `code-reviewer` checks for secrets. No skill does active security analysis (OWASP scan, auth flow review, vulnerability assessment). | Could create a `safe-changes-security-review` skill for targeted security analysis of auth flows, input validation, and common vulnerability patterns. Alternatively, extend `code-diagnosis` with a security-focused mode. |
| **Performance analysis** | Medium | No coverage. No skill profiles code or suggests optimizations. | Could create a `code-performance` skill that profiles bottlenecks, analyzes query performance, and suggests optimizations. Or extend `code-diagnosis` with a performance mode. |
| **Database/migrations** | Low-Medium | `safe-changes-impact-check` mentions DB schema changes but doesn't provide DB-specific guidance (migration safety, rollback plans, data backfill strategies). | Could create a `safe-changes-migration` skill. Or extend `impact-check` with DB-specific checklists when it detects schema changes. |
| **Deployment/release** | Low | No coverage. No skill for deploy checklists, release notes, or go/no-go decisions. | Could create a `session-deploy` skill for pre-deploy checklist and release notes generation. Different from `session-wrapup` (which is session close, not deployment). |
| **Documentation generation** | Low | `meta-update-docs` syncs existing docs. No skill generates API docs, user guides, or architectural decision records (ADRs). | Low priority — most projects have their own doc tooling. Could extend `session-wrapup` to optionally generate changelog entries. |
| **Code scaffolding** | Low | `api-development-api-impl` scaffolds API endpoints. No general scaffolding for other patterns (CLI tools, services, workers, etc.). | Low priority. The `api-impl` model could be replicated for other patterns if demand arises. Not worth creating now. |

---

## Next Steps

### No merges needed
All detected overlaps are Low severity with clear differentiation. No components need to be merged or removed.

### Gaps to consider (prioritized)

- [ ] **Testing strategy** (Medium) — Consider extending `quality-review` to include test coverage analysis, or create `planning-test-strategy`
- [ ] **Security review** (Medium) — Consider a security-focused mode in `code-diagnosis` or a new `safe-changes-security-review` skill
- [ ] **Performance analysis** (Medium) — Consider extending `code-diagnosis` with a performance mode or creating `code-performance`
- [ ] **Database/migrations** (Low-Medium) — Consider extending `safe-changes-impact-check` with DB-specific checklists
- [ ] **Deployment/release** (Low) — Consider `session-deploy` if deployment workflows become common
- [ ] **Documentation generation** (Low) — Not urgent, most projects have own tooling
- [ ] **Code scaffolding** (Low) — Not urgent, replicate `api-impl` pattern if needed

### Maintenance items
- [ ] All 7 Low overlaps have adequate "vs" documentation — no clarification needed
- [ ] Skill count is 20 — healthy size, not bloated
- [ ] All skills have valid frontmatter and match directory names (tests pass)
- [ ] New lifecycle-based categorization in README.md improves discoverability
